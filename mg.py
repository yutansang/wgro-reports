# -*- coding: utf-8 -*-
"""
ç¾è‚¡æ·±åº¦å…¨æ™¯åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨ (US Stock Deep Dive Edition)
ç‰ˆæœ¬: 3.0 (æ·±åº¦å™äº‹é€»è¾‘å¢å¼ºç‰ˆ)
æ–°å¢: 
1. "æ·±åº¦è§£è¯»"æ¨¡å—ï¼šåŒ…å«æ ¸å¿ƒå¤´æ¡ã€ä¸ªè‚¡æ˜¾å¾®é•œã€å®è§‚èƒŒç¦»ã€é£æ ¼éªŒè¯ã€æ“ä½œå»ºè®®ã€‚
2. åŠ¨æ€æ¨ç†å¼•æ“ï¼šèƒ½æ ¹æ®ä¸åŒè¡Œæƒ…ï¼ˆæ™®æ¶¨ã€æ™®è·Œã€è½®åŠ¨ã€èƒŒç¦»ï¼‰è‡ªåŠ¨ç”Ÿæˆå¯¹åº”çš„åˆ†ææ–‡æ¡ˆã€‚
"""

import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime
import warnings

# å¿½ç•¥ pandas çš„æœªæ¥ç‰ˆæœ¬è­¦å‘Š
warnings.simplefilter(action='ignore', category=FutureWarning)

# =============================================================================
# 1. é…ç½®å‚æ•°
# =============================================================================

BENCHMARK_TICKER = 'SPY' 
TIME_PERIODS = {'long_term': 60, 'mid_term': 20, 'short_term': 5}
PERIOD_WEIGHTS = {'long_term': 0.6, 'mid_term': 0.3, 'short_term': 0.1}

# --- èµ„äº§æ¸…å• ---
MACRO_INDICATORS = {
    "VIXææ…ŒæŒ‡æ•°": "^VIX",
    "åå¹´æœŸç¾å€ºæ”¶ç›Šç‡": "^TNX",
    "ç¾å…ƒæŒ‡æ•°": "UUP",
    "WTIåŸæ²¹": "CL=F"
}

SECTOR_ETFS = {
    "ç§‘æŠ€ (XLK)": "XLK",
    "é€šä¿¡ (XLC)": "XLC",
    "å¯é€‰æ¶ˆè´¹ (XLY)": "XLY",
    "é‡‘è (XLF)": "XLF",
    "åŒ»ç–— (XLV)": "XLV",
    "å·¥ä¸š (XLI)": "XLI",
    "èƒ½æº (XLE)": "XLE",
    "å¿…é€‰æ¶ˆè´¹ (XLP)": "XLP",
    "å…¬ç”¨äº‹ä¸š (XLU)": "XLU",
    "åŠå¯¼ä½“ (SMH)": "SMH"
}

WATCHLIST_STOCKS = [
    "NVDA", "AAPL", "MSFT", "AMZN", "GOOGL", "META", "TSLA", 
    "AMD", "AVGO", "TSM", 
    "JPM", "BAC", 
    "LLY", "UNH", 
    "XOM", "CVX", 
    "COST", "WMT", 
    "NFLX", "DIS"
]

ALL_ANALYSIS_ASSETS = list(set(list(MACRO_INDICATORS.values()) + list(SECTOR_ETFS.values()) + WATCHLIST_STOCKS))

COLUMN_TRANSLATIONS = {
    'master_score': 'ç»¼åˆå¤§å¸ˆåˆ† (Alpha)',
    'weighted_z_score_rs': 'åŠ æƒç›¸å¯¹Zå€¼',
    'acceleration': 'åŠ¨èƒ½åŠ é€Ÿåº¦',
    f'z_score_rs_{TIME_PERIODS["long_term"]}d': f'{TIME_PERIODS["long_term"]}æ—¥ç›¸å¯¹è¶‹åŠ¿',
    f'z_score_rs_{TIME_PERIODS["mid_term"]}d': f'{TIME_PERIODS["mid_term"]}æ—¥ç›¸å¯¹è¶‹åŠ¿',
    f'z_score_rs_{TIME_PERIODS["short_term"]}d': f'{TIME_PERIODS["short_term"]}æ—¥ç›¸å¯¹è¶‹åŠ¿'
}

COLUMN_ORDER = [
    'master_score', 
    'weighted_z_score_rs', 
    f'z_score_rs_{TIME_PERIODS["long_term"]}d',
    f'z_score_rs_{TIME_PERIODS["mid_term"]}d',
    f'z_score_rs_{TIME_PERIODS["short_term"]}d',
    'acceleration'
]

# =============================================================================
# 2. æ•°æ®è·å–ä¸è®¡ç®—é€»è¾‘
# =============================================================================
def fetch_data_robust(tickers, period="2y"):
    print(f"æ­£åœ¨ä¸‹è½½ {len(tickers)} ä¸ªç¾è‚¡èµ„äº§æ•°æ®...")
    all_data = []
    try:
        data = yf.download(tickers, period=period, auto_adjust=True, progress=False, group_by='ticker')
        if len(tickers) == 1:
             df = data['Close'].to_frame()
             df.columns = tickers
             return df
        
        extracted_data = {}
        for ticker in tickers:
            try:
                if isinstance(data.columns, pd.MultiIndex): series = data[ticker]['Close']
                else: series = data['Close']
                if not series.empty: extracted_data[ticker] = series
            except KeyError: pass
                
        if not extracted_data: return pd.DataFrame()
        combined_df = pd.DataFrame(extracted_data)
        combined_df.ffill(inplace=True); combined_df.bfill(inplace=True)
        combined_df.dropna(how='all', axis=0, inplace=True)
        return combined_df
    except Exception as e:
        print(f"æ‰¹é‡ä¸‹è½½å‡ºé”™: {e}ï¼Œå°è¯•é€ä¸ªä¸‹è½½...")
        for ticker in tickers:
            try:
                d = yf.download(ticker, period=period, auto_adjust=True, progress=False)['Close']
                if not d.empty: all_data.append(d.rename(ticker))
            except: pass
        return pd.concat(all_data, axis=1) if all_data else pd.DataFrame()

def calculate_professional_momentum_score(price_data, benchmark_price):
    results = []
    ticker_to_name = {v: k for k, v in {**MACRO_INDICATORS, **SECTOR_ETFS}.items()}
    
    for ticker in price_data.columns:
        if ticker == benchmark_price.name: continue
        
        asset_price = price_data[ticker]
        aligned_benchmark = benchmark_price.reindex(asset_price.index).ffill()
        
        is_macro = ticker in MACRO_INDICATORS.values()
        relative_price = asset_price if is_macro else (asset_price / aligned_benchmark).dropna()

        if len(relative_price) < max(TIME_PERIODS.values()): continue
        
        metrics = {'Ticker': ticker}
        weighted_z_score_sum = 0
        
        for term, period_days in TIME_PERIODS.items():
            if len(relative_price) >= period_days:
                rs_returns = (relative_price / relative_price.shift(period_days)) - 1
                mean, std = rs_returns.mean(), rs_returns.std()
                
                if std > 0:
                    z_score = (rs_returns.iloc[-1] - mean) / std
                    metrics[f'z_score_rs_{period_days}d'] = z_score
                    weighted_z_score_sum += z_score * PERIOD_WEIGHTS[term]
                else: weighted_z_score_sum = np.nan
        
        if np.isnan(weighted_z_score_sum): continue
        metrics['weighted_z_score_rs'] = weighted_z_score_sum
        
        lookback_vol = TIME_PERIODS['long_term']
        if len(asset_price) >= lookback_vol:
            annualized_vol = asset_price.pct_change().dropna().tail(lookback_vol).std() * np.sqrt(252)
            metrics['master_score'] = weighted_z_score_sum / annualized_vol if annualized_vol > 0 else 0
        else: continue
        
        results.append(metrics)

    if not results: return pd.DataFrame()
    df = pd.DataFrame(results).dropna().set_index('Ticker')
    
    new_index = []
    for t in df.index: new_index.append(ticker_to_name.get(t, t))
    df.index = new_index
    return df

# =============================================================================
# 3. HTML æŠ¥å‘Šç”Ÿæˆæ¨¡å—
# =============================================================================

### å¸‚åœºæƒ…ç»ª ###
def generate_market_sentiment_module(all_scores_df):
    html = "<h2>ğŸ›ï¸ ç¾è‚¡å¸‚åœºæƒ…ç»ªæŒ‡æ ‡ (Equity Sentiment Gauge)</h2>"
    def get_z(name):
        for n in [name, MACRO_INDICATORS.get(name), SECTOR_ETFS.get(name)]:
            if n in all_scores_df.index: return all_scores_df.loc[n, 'weighted_z_score_rs']
        return 0

    fear = get_z("VIXææ…ŒæŒ‡æ•°") + get_z("åå¹´æœŸç¾å€ºæ”¶ç›Šç‡")
    risk_on = get_z("å¯é€‰æ¶ˆè´¹ (XLY)") - get_z("å¿…é€‰æ¶ˆè´¹ (XLP)")
    tech = get_z("åŠå¯¼ä½“ (SMH)")
    
    score = risk_on + (tech * 0.5) - (fear * 0.8)
    score = np.clip(score * 2.0, -10, 10)
    
    if score > 7: s, c = "æåº¦è´ªå©ª", "#dc3545"
    elif score > 3: s, c = "è´ªå©ª", "#ffc107"
    elif score > -3: s, c = "ä¸­æ€§", "#6c757d"
    elif score > -7: s, c = "ææƒ§", "#28a745"
    else: s, c = "æåº¦ææƒ§", "#17a2b8"
    
    html += f"""
    <div style='text-align:center; margin:20px 0; padding:20px; background:#fff; border-radius:10px; box-shadow:0 2px 10px rgba(0,0,0,0.05);'>
        <div style='font-size:1.5em;'>å½“å‰ç¾è‚¡æƒ…ç»ª: <strong style='color:{c};'>{s}</strong></div>
        <div style='font-size:3.5em; font-weight:bold; margin:15px 0; color:{c}'>{score:.2f}</div>
        <div style='width:80%; margin:auto; background-color:#e9ecef; border-radius:10px; height:25px; position:relative;'>
            <div style='height:100%; width:2px; background-color:#343a40; position:absolute; left:50%;'></div>
            <div style='height:25px; width:25px; background-color:{c}; border:3px solid #fff; border-radius:50%; position:absolute; top:0; left:calc({(score+10)*5}% - 12.5px);'></div>
        </div>
    </div>"""
    return html

### ç»¼åˆåˆ†æ ###
def generate_deep_dive_analysis_html(all_scores_df, correlation_matrix):
    html = "<h2>ğŸ§  æ™ºèƒ½æ·±åº¦æ´å¯Ÿ (AI Deep Dive)</h2>"
    
    # 1. åŠ é€Ÿåº¦
    accelerating = all_scores_df.sort_values('acceleration', ascending=False)
    html += "<h3>1. åŠ¨èƒ½åŠ é€Ÿæ¦œ</h3><ul>"
    for asset, row in accelerating.head(3).iterrows():
        if row['acceleration'] > 0.3:
            html += f"<li><b>ğŸš€ {asset}</b> (åŠ é€Ÿåº¦: +{row['acceleration']:.2f}): çŸ­æœŸçˆ†å‘åŠ›å¼ºï¼Œ5æ—¥è¶‹åŠ¿æ˜¾è‘—ä¼˜äº20æ—¥è¶‹åŠ¿ã€‚</li>"
    html += "</ul>"

    # 2. é£æ ¼æ‰«æ
    html += "<h3 style='margin-top:20px;'>2. é£æ ¼åˆ‡æ¢é›·è¾¾</h3>"
    pivot_groups = [
        {"name": "ç§‘æŠ€æˆé•¿ (Growth)", "assets": ["XLK", "SMH", "NVDA", "QQQ"], "desc": "ç§‘æŠ€/åŠå¯¼ä½“/çº³æŒ‡"},
        {"name": "ä¼ ç»Ÿä»·å€¼ (Value)", "assets": ["XLE", "XLF", "XLI"], "desc": "èƒ½æº/é‡‘è/å·¥ä¸š"},
        {"name": "é˜²å¾¡é¿é™© (Defensive)", "assets": ["XLP", "XLU", "XLV"], "desc": "å…¬ç”¨äº‹ä¸š/å¿…é€‰æ¶ˆè´¹"}
    ]
    ticker_map = {v: k for k, v in {**MACRO_INDICATORS, **SECTOR_ETFS}.items()}
    
    pivot_html = "<table class='pivot-table'><thead><tr><th>æ¿å—é£æ ¼</th><th>é•¿æœŸè¶‹åŠ¿ (60d)</th><th>çŸ­æœŸè¶‹åŠ¿ (5d)</th><th>çŠ¶æ€åˆ¤å®š</th></tr></thead><tbody>"
    for group in pivot_groups:
        target_indices = []
        for ticker in group['assets']:
            real_name = ticker_map.get(ticker, ticker)
            if real_name in all_scores_df.index: target_indices.append(real_name)
        
        if not target_indices: continue
        rows = all_scores_df.loc[target_indices]
        lt, st = rows[f'z_score_rs_{TIME_PERIODS["long_term"]}d'].mean(), rows[f'z_score_rs_{TIME_PERIODS["short_term"]}d'].mean()
        
        lt_s = "<span style='color:#28a745'>å¼ºåŠ¿</span>" if lt>0 else "<span style='color:#dc3545'>å¼±åŠ¿</span>"
        st_s = "<span style='color:#28a745'>èµ°å¼º</span>" if st>0 else "<span style='color:#dc3545'>èµ°å¼±</span>"
        status = "è¶‹åŠ¿å»¶ç»­"
        if lt<-0.1 and st>0.1: status="ğŸ“ˆ åº•éƒ¨åè½¬ (å…³æ³¨)"
        elif lt>0.1 and st<-0.1: status="ğŸ“‰ é¡¶éƒ¨å›æ’¤ (è­¦æƒ•)"
        
        pivot_html += f"<tr><td><b>{group['name']}</b><br><span style='font-size:0.8em;color:#888'>{group['desc']}</span></td><td>{lt_s} ({lt:.2f})</td><td>{st_s} ({st:.2f})</td><td><b>{status}</b></td></tr>"
    html += pivot_html + "</tbody></table>"

    # 3. ç­–ç•¥ (ç®€å•ç‰ˆ)
    html += "<h3 style='margin-top:20px;'>3. äº¤æ˜“ç­–ç•¥å»ºè®®</h3>"
    longs = all_scores_df[(all_scores_df['master_score']>3) & (all_scores_df['acceleration']>-0.5)].sort_values('master_score', ascending=False).head(3)
    if not longs.empty:
        html += "<h4>ğŸŒŸ æ ¸å¿ƒå¤šå¤´</h4><ul>"
        for asset, row in longs.iterrows(): html += f"<li><b>{asset}</b>: å¤§å¸ˆåˆ† {row['master_score']:.2f}ï¼Œè¶‹åŠ¿ç¨³å¥ã€‚</li>"
        html += "</ul>"

    return html

### [NEW] æ·±åº¦è§£è¯»æ¨¡å— (å®Œå…¨åŠ¨æ€é€»è¾‘) ###
def generate_deep_interpretation_module(all_scores_df):
    html = "<h2>ğŸ§ æ·±åº¦è§£è¯» (Data-Driven Narrative)</h2>"
    ticker_map = {v: k for k, v in {**MACRO_INDICATORS, **SECTOR_ETFS}.items()}

    # è¾…åŠ©æ•°æ®è·å–
    def get_val(name, col):
        real_name = ticker_map.get(name, name)
        if real_name in all_scores_df.index: return all_scores_df.loc[real_name, col]
        return None
    
    # --- 1. æ ¸å¿ƒå¤´æ¡ (Core Headline) ---
    html += "<h3>1. æ ¸å¿ƒå¤´æ¡ï¼šèµ„é‡‘æµå‘ä½•æ–¹ï¼Ÿ</h3>"
    
    # æ‰¾å‡ºåŠ¨èƒ½æœ€å¼ºå’Œæœ€å¼±çš„æ¿å—
    sectors_df = all_scores_df[all_scores_df.index.isin(SECTOR_ETFS.keys())]
    if not sectors_df.empty:
        best_sector = sectors_df.sort_values('acceleration', ascending=False).iloc[0]
        worst_sector = sectors_df.sort_values('acceleration', ascending=True).iloc[0]
        
        # åˆ¤å®šå¸‚åœºå‰§æœ¬
        headline_text = ""
        if best_sector['acceleration'] > 1.0 and worst_sector['acceleration'] < -1.0:
            headline_text = f"<b>æš´åŠ›é£æ ¼åˆ‡æ¢ (Great Rotation)</b>ã€‚èµ„é‡‘æ­£åœ¨ä»<b>{worst_sector.name}</b>æ¿å—ææ…Œå‡ºé€ƒï¼ˆåŠ é€Ÿåº¦ {worst_sector['acceleration']:.2f}ï¼‰ï¼Œå¹¶æš´åŠ›æ¶Œå…¥<b>{best_sector.name}</b>ï¼ˆåŠ é€Ÿåº¦ +{best_sector['acceleration']:.2f}ï¼‰ã€‚è¿™ä¸æ˜¯æ™®æ¶¨ï¼Œè¿™æ˜¯ä¸€åœºè¡€è…¥çš„è°ƒä»“æ¢è‚¡ã€‚"
        elif best_sector['acceleration'] > 0.5 and worst_sector['acceleration'] > -0.5:
            headline_text = f"<b>å¤šå¤´å…±æŒ¯ (Broad Rally)</b>ã€‚å¸‚åœºå‘ˆç°æ™®æ¶¨æ€åŠ¿ï¼Œé¢†å¤´ç¾Šæ˜¯<b>{best_sector.name}</b>ã€‚å¹¶æœªå‡ºç°æ˜æ˜¾çš„æ¿å—æºƒè´¥ï¼Œå¸‚åœºé£é™©åå¥½è¾ƒé«˜ã€‚"
        elif best_sector['acceleration'] < 0.5 and worst_sector['acceleration'] < -1.0:
            headline_text = f"<b>é¿é™©æ¨¡å¼ (Flight to Safety)</b>ã€‚å¸‚åœºç¼ºä¹æ˜æ˜¾çš„è¿›æ”»çƒ­ç‚¹ï¼Œè€Œ<b>{worst_sector.name}</b>æ­£åœ¨é­å—é‡æŒ«ã€‚å»ºè®®ä¿æŒè°¨æ…ã€‚"
        else:
            headline_text = f"<b>éœ‡è¡åˆ†åŒ–</b>ã€‚æœ€å¼ºçš„æ¿å—æ˜¯{best_sector.name}ï¼Œæœ€å¼±çš„æ˜¯{worst_sector.name}ï¼Œä½†å¼ºåº¦å‡æœªè¾¾åˆ°æç«¯æ°´å¹³ï¼Œå¸‚åœºå¤„äºå­˜é‡åšå¼ˆé˜¶æ®µã€‚"
            
        html += f"<p>{headline_text}</p>"

    # --- 2. ä¸ªè‚¡æ˜¾å¾®é•œ (Stock Microscope) ---
    html += "<h3 style='margin-top:20px;'>2. ä¸ªè‚¡æ˜¾å¾®é•œï¼šå·¨å¤´çš„æ‚²å–œ</h3><ul>"
    
    # æ‰«æä¸ªè‚¡ (WATCHLIST)
    stock_rows = []
    for s in WATCHLIST_STOCKS:
        rn = ticker_map.get(s, s)
        if rn in all_scores_df.index: stock_rows.append(all_scores_df.loc[rn])
    
    if stock_rows:
        stocks_df = pd.DataFrame(stock_rows)
        
        # åœºæ™¯A: æ²‰ç¡å·¨äºº (é•¿æœŸå·®ï¼ŒçŸ­æœŸçˆ†å‘)
        waking = stocks_df[(stocks_df['master_score'] < -1) & (stocks_df['acceleration'] > 1.0)]
        if not waking.empty:
            s = waking.iloc[0]
            html += f"<li><b>ğŸ‚ æ²‰ç¡å·¨äººè‹é†’ ({s.name})</b>: å®ƒçš„æ€»åˆ†å¾ˆä½({s['master_score']:.2f})ï¼Œè¯´æ˜è°ƒæ•´äº†å¾ˆä¹…ã€‚ä½†çœ‹å®ƒçš„åŠ é€Ÿåº¦(+{s['acceleration']:.2f})ï¼è¿™æ˜¯å…¸å‹çš„<b>åº•éƒ¨åè½¬</b>ä¿¡å·ï¼Œå³ä¾§äº¤æ˜“æœºä¼šå¯èƒ½å·²ç»å‡ºç°ã€‚</li>"
        
        # åœºæ™¯B: ç¨³å¦‚æ³°å±± (é•¿æœŸå¥½ï¼ŒçŸ­æœŸç¨³)
        steady = stocks_df[(stocks_df['master_score'] > 3) & (stocks_df['acceleration'] > -0.5)].sort_values('master_score', ascending=False)
        if not steady.empty:
            s = steady.iloc[0]
            html += f"<li><b>ğŸ‘‘ ç¨³å¦‚æ³°å±± ({s.name})</b>: å½“ä¹‹æ— æ„§çš„æ ¸å¿ƒå¤šå¤´ã€‚å¤§å¸ˆåˆ†é«˜è¾¾ {s['master_score']:.2f}ï¼Œå…¨å‘¨æœŸè¶‹åŠ¿å¥åº·ï¼Œæ˜¯æŒä»“çš„å®šæµ·ç¥é’ˆã€‚</li>"
            
        # åœºæ™¯C: æ‰è½çš„é£åˆ€ (é•¿æœŸå·®ï¼ŒçŸ­æœŸæ›´å·®)
        falling = stocks_df[(stocks_df['master_score'] < -3) & (stocks_df['acceleration'] < -0.5)].sort_values('master_score', ascending=True)
        if not falling.empty:
            s = falling.iloc[0]
            html += f"<li><b>ğŸ”ª æ‰è½çš„é£åˆ€ ({s.name})</b>: åƒä¸‡ä¸è¦å»æ¥ã€‚å¤§å¸ˆåˆ†æä½({s['master_score']:.2f})ä¸”è¿˜åœ¨åŠ é€Ÿä¸‹è·Œï¼Œè¯´æ˜åŸºæœ¬é¢å¯èƒ½æœ‰ç¡¬ä¼¤ï¼Œ<b>åšå†³å›é¿</b>ã€‚</li>"
            
    html += "</ul>"

    # --- 3. å®è§‚èƒŒç¦»è­¦ç¤º (Macro Divergence) ---
    html += "<h3 style='margin-top:20px;'>3. å®è§‚èƒŒç¦»è­¦ç¤º</h3>"
    tnx_z = get_val("åå¹´æœŸç¾å€ºæ”¶ç›Šç‡", 'z_score_rs_5d')
    xlk_z = get_val("ç§‘æŠ€ (XLK)", 'z_score_rs_5d')
    
    if tnx_z is not None and xlk_z is not None:
        if tnx_z > 0.5 and xlk_z > 0.5:
            html += f"<p>âš ï¸ <b>å¼‚å¸¸èƒŒç¦»ï¼</b>ç¾å€ºæ”¶ç›Šç‡é£™å‡(5d Z={tnx_z:.2f})é€šå¸¸åˆ©ç©ºç§‘æŠ€è‚¡ï¼Œä½†ç§‘æŠ€è‚¡å´åœ¨é¡¶é£ä½œæ¡ˆ(5d Z={xlk_z:.2f})ã€‚è¿™è¦ä¹ˆè¯´æ˜ç§‘æŠ€è‚¡åŸºæœ¬é¢å¼ºåˆ°æ— è§†åˆ©ç‡ï¼Œè¦ä¹ˆæ˜¯ä¸€æ¬¡<b>ä¸å¯æŒç»­çš„é€¼ç©º</b>ï¼Œéœ€è­¦æƒ•æ”¶ç›Šç‡ç»§ç»­ä¸Šè¡Œå¸¦æ¥çš„è¡¥è·Œé£é™©ã€‚</p>"
        elif tnx_z < -0.5 and xlk_z > 0.5:
            html += f"<p>âœ… <b>é¡ºé£é¡ºæ°´ã€‚</b>ç¾å€ºæ”¶ç›Šç‡ä¸‹è¡Œ(5d Z={tnx_z:.2f})ï¼Œä¸ºç§‘æŠ€è‚¡çš„ä¸Šæ¶¨æä¾›äº†å®Œç¾çš„æµåŠ¨æ€§ç¯å¢ƒï¼Œè¿™ç§ä¸Šæ¶¨é€šå¸¸æ¯”è¾ƒå¥åº·ã€‚</p>"
        elif tnx_z > 0.5 and xlk_z < -0.5:
            html += f"<p>ğŸ“‰ <b>æ•™ç§‘ä¹¦å¼å‹åˆ¶ã€‚</b>åˆ©ç‡ä¸Šè¡Œ(5d Z={tnx_z:.2f})æ­£åœ¨ç²¾å‡†æ‰“å‡»é«˜ä¼°å€¼çš„ç§‘æŠ€è‚¡ï¼Œè¿™æ˜¯æ ‡å‡†çš„å®è§‚é€»è¾‘ï¼Œå»ºè®®ç­‰å¾…åˆ©ç‡ä¼ç¨³ã€‚</p>"
        else:
            html += "<p>å½“å‰å®è§‚å› å­ä¸è‚¡å¸‚çš„å…³ç³»å¤„äºæ­£å¸¸æ³¢åŠ¨èŒƒå›´ï¼Œæœªè§æ˜¾è‘—å¼‚å¸¸ã€‚</p>"
    else: html += "<p>å®è§‚æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤å®šã€‚</p>"

    # --- 4. é£æ ¼æ‰«æéªŒè¯ (Style Check) ---
    html += "<h3 style='margin-top:20px;'>4. é£æ ¼æ‰«æéªŒè¯</h3>"
    # æ£€æŸ¥ Value (ä¼ ç»Ÿä»·å€¼) çš„çŠ¶æ€
    val_assets = ["XLE", "XLF", "XLI"]
    val_acc_sum = 0
    count = 0
    for a in val_assets:
        acc = get_val(a, 'acceleration')
        if acc is not None: 
            val_acc_sum += acc
            count += 1
    
    avg_acc = val_acc_sum / count if count else 0
    if avg_acc > 0.3:
        html += f"<p><b>ä¼ ç»Ÿä»·å€¼ (Value) æ­£åœ¨åæ”»</b> (å¹³å‡åŠ é€Ÿåº¦ +{avg_acc:.2f})ã€‚å¦‚æœæ­¤æ—¶ç§‘æŠ€è‚¡ä¹Ÿåœ¨æ¶¨ï¼Œè¯´æ˜æ˜¯å¤è‹äº¤æ˜“ï¼›å¦‚æœç§‘æŠ€è‚¡åœ¨è·Œï¼Œè¯´æ˜æ˜¯é˜²å¾¡æ€§è½®åŠ¨ã€‚è¯·ç»“åˆä¸Šæ–‡åˆ¤æ–­ã€‚</p>"
    elif avg_acc < -0.3:
        html += f"<p><b>ä¼ ç»Ÿä»·å€¼ (Value) æ­£åœ¨å¤±è¡€</b> (å¹³å‡åŠ é€Ÿåº¦ {avg_acc:.2f})ã€‚èµ„é‡‘å¯èƒ½æ­£åœ¨æŠ›å¼ƒæ—§ç»æµï¼Œæµå‘æˆé•¿è‚¡æˆ–ç°é‡‘ã€‚</p>"
    else:
        html += "<p>ä¼ ç»Ÿä»·å€¼é£æ ¼è¡¨ç°å¹³ç¨³ï¼Œå¸‚åœºä¸»è¦çŸ›ç›¾å¯èƒ½é›†ä¸­åœ¨æˆé•¿æ¿å—å†…éƒ¨ã€‚</p>"

    # --- 5. æ“ä½œå»ºè®® (Actionable) ---
    html += "<h3 style='margin-top:20px;'>5. æ“ä½œå»ºè®® (åŸºäºæ•°æ®æ¨ç†)</h3><ul>"
    
    # åŠ¨æ€ç”Ÿæˆ
    top_buy = all_scores_df.sort_values('acceleration', ascending=False).head(1)
    top_sell = all_scores_df.sort_values('acceleration', ascending=True).head(1)
    
    if not top_buy.empty:
        a = top_buy.iloc[0]
        html += f"<li><b>ğŸŸ¢ åšå¤šæ–¹å‘</b>: å…³æ³¨ <b>{a.name}</b>ã€‚åŠ¨èƒ½åˆšåˆšç¿»æ­£/åŠ é€Ÿï¼Œçˆ†å‘åŠ›æœ€å¼ºï¼Œé€‚åˆè¿½å‡»å³ä¾§ã€‚</li>"
    if not top_sell.empty:
        a = top_sell.iloc[0]
        html += f"<li><b>ğŸ”´ æ­¢ç›ˆ/åšç©ºæ–¹å‘</b>: å›é¿ <b>{a.name}</b>ã€‚å®ƒæ­£åœ¨é­å—æœ€å‰§çƒˆçš„èµ„é‡‘æŠ›å”®ï¼ŒçŸ­æœŸä¸‹è¡Œæƒ¯æ€§æå¤§ï¼Œä¸è¦æ¥é£åˆ€ã€‚</li>"
        
    html += "</ul>"
    
    return html

# --- é€šç”¨å‡½æ•° ---
def colorize(val):
    if isinstance(val, (int, float)):
        color = '#28a745' if val > 0 else ('#dc3545' if val < 0 else '#6c757d')
        if abs(val) > 0.7:
             return f'<span style="background-color: #ffc107; color: #343a40; font-weight: bold;">{val:.2f}</span>'
        return f'<span style="color: {color}; font-weight: bold;">{val:.2f}</span>'
    return val

def generate_html_table(df, title):
    if df is None or df.empty: return ""
    df_display = df.copy()
    ordered_cols = [c for c in COLUMN_ORDER if c in df_display.columns]
    df_display = df_display[ordered_cols]
    df_display.rename(columns=COLUMN_TRANSLATIONS, inplace=True)
    
    formatters = {col: colorize for col in df_display.columns if pd.api.types.is_numeric_dtype(df_display[col])}
    html = df_display.to_html(classes='styled-table', escape=False, border=0, justify='center', formatters=formatters)
    return f"<h2>{title}</h2>\n{html}"

def create_html_report(all_html_sections, filename="mg.html"):

    css = """<style>
        body{font-family:"Segoe UI",Roboto,Helvetica,Arial,sans-serif;padding:2rem;background:#f0f2f5;color:#333}
        h1{text-align:center;color:#1a73e8;border-bottom:3px solid #1a73e8;padding-bottom:10px}
        h2{color:#444;border-left:5px solid #1a73e8;padding-left:10px;margin-top:30px;background:#fff;padding:10px}
        h3{color:#1a73e8;margin-top:20px} h4{color:#d93025;margin-top:15px}
        .container{max-width:1200px;margin:auto;background:#fff;padding:30px;border-radius:12px;box-shadow:0 6px 15px rgba(0,0,0,.05)}
        .styled-table, .pivot-table{width:100%;border-collapse:collapse;margin:20px 0;box-shadow:0 0 10px rgba(0,0,0,0.05)}
        .styled-table th, .pivot-table th{background:#1a73e8;color:#fff;padding:12px;text-align:center}
        .styled-table td, .pivot-table td{padding:10px;border-bottom:1px solid #ddd;text-align:center}
        .styled-table tr:nth-child(even){background:#f9f9f9}
        li{margin-bottom:8px} b{font-weight:700;color:#333}
    </style>"""
    html_t = f"<!DOCTYPE html><html><head><meta charset='UTF-8'><title>ç¾è‚¡æŠ¥å‘Š</title>{css}</head><body><div class='container'><h1>ğŸ‡ºğŸ‡¸ ç¾è‚¡å…¨æ™¯äº¤æ˜“å†³ç­–çœ‹æ¿ (v3.0 æ·±åº¦è§£è¯»ç‰ˆ)</h1><p style='text-align:center;color:#888'>{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>{''.join(all_html_sections)}</div></body></html>"
    with open(filename, 'w', encoding='utf-8') as f: f.write(html_t)
    print(f"æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")

# =============================================================================
# 4. ä¸»ç¨‹åº
# =============================================================================
if __name__ == '__main__':
    print("å¯åŠ¨ç¾è‚¡æ·±åº¦åˆ†æå¼•æ“ (v3.0)...")
    all_tickers = list(set(ALL_ANALYSIS_ASSETS + [BENCHMARK_TICKER]))
    price_data = fetch_data_robust(all_tickers, period="2y")
    
    if not price_data.empty and BENCHMARK_TICKER in price_data.columns:
        benchmark_data = price_data[BENCHMARK_TICKER]
        
        print("æ­£åœ¨è®¡ç®—åŠ¨é‡...")
        full_analysis_df = calculate_professional_momentum_score(price_data, benchmark_data)
        
        # å…¨å±€è®¡ç®—åŠ é€Ÿåº¦
        st_col = f'z_score_rs_{TIME_PERIODS["short_term"]}d'
        mt_col = f'z_score_rs_{TIME_PERIODS["mid_term"]}d'
        if st_col in full_analysis_df.columns and mt_col in full_analysis_df.columns:
            full_analysis_df['acceleration'] = full_analysis_df[st_col] - full_analysis_df[mt_col]
        else:
            full_analysis_df['acceleration'] = 0
        
        print("æ­£åœ¨è®¡ç®—ç›¸å…³æ€§...")
        corr_tickers = [t for t in WATCHLIST_STOCKS[:10] + list(MACRO_INDICATORS.values()) if t in price_data.columns]
        corr_matrix = pd.DataFrame()
        if corr_tickers:
            mapper = {**MACRO_INDICATORS, **SECTOR_ETFS}
            corr_matrix = price_data[corr_tickers].pct_change().dropna().tail(60).corr()
            corr_matrix.rename(index=mapper, columns=mapper, inplace=True)

        html_sections = []
        if not full_analysis_df.empty:
            html_sections.append(generate_market_sentiment_module(full_analysis_df))
            html_sections.append(generate_deep_dive_analysis_html(full_analysis_df, corr_matrix))
            
            # [æ–°å¢] æ’å…¥æ·±åº¦è§£è¯»æ¨¡å—
            html_sections.append(generate_deep_interpretation_module(full_analysis_df))
            
            groups = [
                ("ğŸ“Š åå¤§æ¿å—åŠ¨é‡æ’å (vs SPY)", SECTOR_ETFS.values()),
                ("ğŸ”¥ æ ¸å¿ƒå…³æ³¨ä¸ªè‚¡æ’å (vs SPY)", WATCHLIST_STOCKS),
                ("ğŸŒ å®è§‚æŒ‡æ ‡è¶‹åŠ¿", MACRO_INDICATORS.values())
            ]
            
            reverse_map = {v: k for k, v in {**MACRO_INDICATORS, **SECTOR_ETFS}.items()}
            for title, tickers in groups:
                target_names = []
                for t in tickers:
                    if t in full_analysis_df.index: target_names.append(t)
                    elif reverse_map.get(t) in full_analysis_df.index: target_names.append(reverse_map.get(t))
                
                subset = full_analysis_df.loc[target_names].sort_values('master_score', ascending=False)
                html_sections.append(generate_html_table(subset, title))

        create_html_report(html_sections)
    else:
        print("æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆã€‚")

